{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f70176",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:11.510386Z",
     "iopub.status.busy": "2023-05-05T06:19:11.509338Z",
     "iopub.status.idle": "2023-05-05T06:19:11.528345Z",
     "shell.execute_reply": "2023-05-05T06:19:11.526882Z"
    },
    "papermill": {
     "duration": 0.034622,
     "end_time": "2023-05-05T06:19:11.531931",
     "exception": false,
     "start_time": "2023-05-05T06:19:11.497309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d65f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:11.551264Z",
     "iopub.status.busy": "2023-05-05T06:19:11.550767Z",
     "iopub.status.idle": "2023-05-05T06:19:21.858466Z",
     "shell.execute_reply": "2023-05-05T06:19:21.856841Z"
    },
    "papermill": {
     "duration": 10.321691,
     "end_time": "2023-05-05T06:19:21.862270",
     "exception": false,
     "start_time": "2023-05-05T06:19:11.540579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, re, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "import json, re, string, unicodedata\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13705c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:21.883074Z",
     "iopub.status.busy": "2023-05-05T06:19:21.881131Z",
     "iopub.status.idle": "2023-05-05T06:19:21.909007Z",
     "shell.execute_reply": "2023-05-05T06:19:21.907687Z"
    },
    "papermill": {
     "duration": 0.04118,
     "end_time": "2023-05-05T06:19:21.912153",
     "exception": false,
     "start_time": "2023-05-05T06:19:21.870973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "que, ans = [], []\n",
    "with open('../input/simple-dialogs-for-chatbot/dialogs.txt','r') as f:\n",
    "    for line in f:\n",
    "        line = line.split('\\t')\n",
    "        que.append(line[0])\n",
    "        ans.append(line[1].replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eaa3226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:21.931906Z",
     "iopub.status.busy": "2023-05-05T06:19:21.931473Z",
     "iopub.status.idle": "2023-05-05T06:19:21.941042Z",
     "shell.execute_reply": "2023-05-05T06:19:21.939670Z"
    },
    "papermill": {
     "duration": 0.022928,
     "end_time": "2023-05-05T06:19:21.943880",
     "exception": false,
     "start_time": "2023-05-05T06:19:21.920952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'que':que,'ans':ans})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a73e80f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:21.963090Z",
     "iopub.status.busy": "2023-05-05T06:19:21.962572Z",
     "iopub.status.idle": "2023-05-05T06:19:21.969041Z",
     "shell.execute_reply": "2023-05-05T06:19:21.967624Z"
    },
    "papermill": {
     "duration": 0.019112,
     "end_time": "2023-05-05T06:19:21.971843",
     "exception": false,
     "start_time": "2023-05-05T06:19:21.952731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e4235b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:21.995534Z",
     "iopub.status.busy": "2023-05-05T06:19:21.994859Z",
     "iopub.status.idle": "2023-05-05T06:19:22.025854Z",
     "shell.execute_reply": "2023-05-05T06:19:22.024820Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.046896,
     "end_time": "2023-05-05T06:19:22.028785",
     "exception": false,
     "start_time": "2023-05-05T06:19:21.981889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contractions_dict = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"doesn’t\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"don’t\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y’all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\",\n",
    "\"ain’t\": \"am not\",\n",
    "\"aren’t\": \"are not\",\n",
    "\"can’t\": \"cannot\",\n",
    "\"can’t’ve\": \"cannot have\",\n",
    "\"’cause\": \"because\",\n",
    "\"could’ve\": \"could have\",\n",
    "\"couldn’t\": \"could not\",\n",
    "\"couldn’t’ve\": \"could not have\",\n",
    "\"didn’t\": \"did not\",\n",
    "\"doesn’t\": \"does not\",\n",
    "\"don’t\": \"do not\",\n",
    "\"don’t\": \"do not\",\n",
    "\"hadn’t\": \"had not\",\n",
    "\"hadn’t’ve\": \"had not have\",\n",
    "\"hasn’t\": \"has not\",\n",
    "\"haven’t\": \"have not\",\n",
    "\"he’d\": \"he had\",\n",
    "\"he’d’ve\": \"he would have\",\n",
    "\"he’ll\": \"he will\",\n",
    "\"he’ll’ve\": \"he will have\",\n",
    "\"he’s\": \"he is\",\n",
    "\"how’d\": \"how did\",\n",
    "\"how’d’y\": \"how do you\",\n",
    "\"how’ll\": \"how will\",\n",
    "\"how’s\": \"how is\",\n",
    "\"i’d\": \"i would\",\n",
    "\"i’d’ve\": \"i would have\",\n",
    "\"i’ll\": \"i will\",\n",
    "\"i’ll’ve\": \"i will have\",\n",
    "\"i’m\": \"i am\",\n",
    "\"i’ve\": \"i have\",\n",
    "\"isn’t\": \"is not\",\n",
    "\"it’d\": \"it would\",\n",
    "\"it’d’ve\": \"it would have\",\n",
    "\"it’ll\": \"it will\",\n",
    "\"it’ll’ve\": \"it will have\",\n",
    "\"it’s\": \"it is\",\n",
    "\"let’s\": \"let us\",\n",
    "\"ma’am\": \"madam\",\n",
    "\"mayn’t\": \"may not\",\n",
    "\"might’ve\": \"might have\",\n",
    "\"mightn’t\": \"might not\",\n",
    "\"mightn’t’ve\": \"might not have\",\n",
    "\"must’ve\": \"must have\",\n",
    "\"mustn’t\": \"must not\",\n",
    "\"mustn’t’ve\": \"must not have\",\n",
    "\"needn’t\": \"need not\",\n",
    "\"needn’t’ve\": \"need not have\",\n",
    "\"o’clock\": \"of the clock\",\n",
    "\"oughtn’t\": \"ought not\",\n",
    "\"oughtn’t’ve\": \"ought not have\",\n",
    "\"shan’t\": \"shall not\",\n",
    "\"sha’n’t\": \"shall not\",\n",
    "\"shan’t’ve\": \"shall not have\",\n",
    "\"she’d\": \"she would\",\n",
    "\"she’d’ve\": \"she would have\",\n",
    "\"she’ll\": \"she will\",\n",
    "\"she’ll’ve\": \"she will have\",\n",
    "\"she’s\": \"she is\",\n",
    "\"should’ve\": \"should have\",\n",
    "\"shouldn’t\": \"should not\",\n",
    "\"shouldn’t’ve\": \"should not have\",\n",
    "\"so’ve\": \"so have\",\n",
    "\"so’s\": \"so is\",\n",
    "\"that’d\": \"that would\",\n",
    "\"that’d’ve\": \"that would have\",\n",
    "\"that’s\": \"that is\",\n",
    "\"there’d\": \"there would\",\n",
    "\"there’d’ve\": \"there would have\",\n",
    "\"there’s\": \"there is\",\n",
    "\"they’d\": \"they would\",\n",
    "\"they’d’ve\": \"they would have\",\n",
    "\"they’ll\": \"they will\",\n",
    "\"they’ll’ve\": \"they will have\",\n",
    "\"they’re\": \"they are\",\n",
    "\"they’ve\": \"they have\",\n",
    "\"to’ve\": \"to have\",\n",
    "\"wasn’t\": \"was not\",\n",
    "\"we’d\": \"we would\",\n",
    "\"we’d’ve\": \"we would have\",\n",
    "\"we’ll\": \"we will\",\n",
    "\"we’ll’ve\": \"we will have\",\n",
    "\"we’re\": \"we are\",\n",
    "\"we’ve\": \"we have\",\n",
    "\"weren’t\": \"were not\",\n",
    "\"what’ll\": \"what will\",\n",
    "\"what’ll’ve\": \"what will have\",\n",
    "\"what’re\": \"what are\",\n",
    "\"what’s\": \"what is\",\n",
    "\"what’ve\": \"what have\",\n",
    "\"when’s\": \"when is\",\n",
    "\"when’ve\": \"when have\",\n",
    "\"where’d\": \"where did\",\n",
    "\"where’s\": \"where is\",\n",
    "\"where’ve\": \"where have\",\n",
    "\"who’ll\": \"who will\",\n",
    "\"who’ll’ve\": \"who will have\",\n",
    "\"who’s\": \"who is\",\n",
    "\"who’ve\": \"who have\",\n",
    "\"why’s\": \"why is\",\n",
    "\"why’ve\": \"why have\",\n",
    "\"will’ve\": \"will have\",\n",
    "\"won’t\": \"will not\",\n",
    "\"won’t’ve\": \"will not have\",\n",
    "\"would’ve\": \"would have\",\n",
    "\"wouldn’t\": \"would not\",\n",
    "\"wouldn’t’ve\": \"would not have\",\n",
    "\"y’all\": \"you all\",\n",
    "\"y’all\": \"you all\",\n",
    "\"y’all’d\": \"you all would\",\n",
    "\"y’all’d’ve\": \"you all would have\",\n",
    "\"y’all’re\": \"you all are\",\n",
    "\"y’all’ve\": \"you all have\",\n",
    "\"you’d\": \"you would\",\n",
    "\"you’d’ve\": \"you would have\",\n",
    "\"you’ll\": \"you will\",\n",
    "\"you’ll’ve\": \"you will have\",\n",
    "\"you’re\": \"you are\",\n",
    "\"you’ve\": \"you have\",\n",
    "\"n't\": \"not\",\n",
    "\"n'\": \"ng\",\n",
    "\"'bout\": \"about\",\n",
    "\"'til\": \"until\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da9688d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.047937Z",
     "iopub.status.busy": "2023-05-05T06:19:22.047182Z",
     "iopub.status.idle": "2023-05-05T06:19:22.059832Z",
     "shell.execute_reply": "2023-05-05T06:19:22.058822Z"
    },
    "papermill": {
     "duration": 0.025408,
     "end_time": "2023-05-05T06:19:22.062623",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.037215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "con_re = re.compile('(%s)'%'|'.join(contractions_dict.keys()))\n",
    "def expand_contractions(raw):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return con_re.sub(replace, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5cdb915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.084159Z",
     "iopub.status.busy": "2023-05-05T06:19:22.083415Z",
     "iopub.status.idle": "2023-05-05T06:19:22.090835Z",
     "shell.execute_reply": "2023-05-05T06:19:22.089334Z"
    },
    "papermill": {
     "duration": 0.021896,
     "end_time": "2023-05-05T06:19:22.093842",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.071946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = unicode_to_ascii(text)\n",
    "    text = expand_contractions(text)\n",
    "    text = ''.join(w for w in text if w not in string.punctuation).strip()\n",
    "    text =  \"<sos> \" +  text + \" <eos>\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd4fff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.113678Z",
     "iopub.status.busy": "2023-05-05T06:19:22.112990Z",
     "iopub.status.idle": "2023-05-05T06:19:22.386676Z",
     "shell.execute_reply": "2023-05-05T06:19:22.385340Z"
    },
    "papermill": {
     "duration": 0.28714,
     "end_time": "2023-05-05T06:19:22.390020",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.102880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.que = df.que.apply(clean_text)\n",
    "df.ans = df.ans.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f977bcf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.409305Z",
     "iopub.status.busy": "2023-05-05T06:19:22.408810Z",
     "iopub.status.idle": "2023-05-05T06:19:22.416101Z",
     "shell.execute_reply": "2023-05-05T06:19:22.414697Z"
    },
    "papermill": {
     "duration": 0.020308,
     "end_time": "2023-05-05T06:19:22.418960",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.398652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "que = df.que.values.tolist()\n",
    "ans = df.ans.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d121e7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.438350Z",
     "iopub.status.busy": "2023-05-05T06:19:22.437463Z",
     "iopub.status.idle": "2023-05-05T06:19:22.444987Z",
     "shell.execute_reply": "2023-05-05T06:19:22.443690Z"
    },
    "papermill": {
     "duration": 0.020353,
     "end_time": "2023-05-05T06:19:22.447865",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.427512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    token = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    token.fit_on_texts(lang)\n",
    "    tensor = token.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c56e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.467347Z",
     "iopub.status.busy": "2023-05-05T06:19:22.466417Z",
     "iopub.status.idle": "2023-05-05T06:19:22.639151Z",
     "shell.execute_reply": "2023-05-05T06:19:22.637939Z"
    },
    "papermill": {
     "duration": 0.186124,
     "end_time": "2023-05-05T06:19:22.642332",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.456208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_tensor, input_lang = tokenize(que)\n",
    "target_tensor, target_lang = tokenize(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa31963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.661732Z",
     "iopub.status.busy": "2023-05-05T06:19:22.660870Z",
     "iopub.status.idle": "2023-05-05T06:19:22.669150Z",
     "shell.execute_reply": "2023-05-05T06:19:22.667197Z"
    },
    "papermill": {
     "duration": 0.021002,
     "end_time": "2023-05-05T06:19:22.671867",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.650865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 22\n"
     ]
    }
   ],
   "source": [
    "max_len_target, max_len_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "print(max_len_target, max_len_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "674bef65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.691727Z",
     "iopub.status.busy": "2023-05-05T06:19:22.691200Z",
     "iopub.status.idle": "2023-05-05T06:19:22.701020Z",
     "shell.execute_reply": "2023-05-05T06:19:22.699623Z"
    },
    "papermill": {
     "duration": 0.023687,
     "end_time": "2023-05-05T06:19:22.704077",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.680390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = tts(input_tensor, target_tensor, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd072590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.724592Z",
     "iopub.status.busy": "2023-05-05T06:19:22.724111Z",
     "iopub.status.idle": "2023-05-05T06:19:22.974524Z",
     "shell.execute_reply": "2023-05-05T06:19:22.973544Z"
    },
    "papermill": {
     "duration": 0.263288,
     "end_time": "2023-05-05T06:19:22.977201",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.713913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 22]), TensorShape([64, 22]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_size = len(xtr)\n",
    "batch_size = 64\n",
    "steps_per_epoch = buffer_size//batch_size\n",
    "emb_dim = 256\n",
    "units = 1024\n",
    "\n",
    "voc_in_size = len(input_lang.word_index)+1\n",
    "voc_tar_size = len(target_lang.word_index)+1\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((xtr,ytr)).shuffle(buffer_size)\n",
    "ds = ds.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "exm_in_bat, exm_tar_bat = next(iter(ds))\n",
    "exm_in_bat.shape, exm_tar_bat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caa4e8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:22.997920Z",
     "iopub.status.busy": "2023-05-05T06:19:22.997067Z",
     "iopub.status.idle": "2023-05-05T06:19:23.006526Z",
     "shell.execute_reply": "2023-05-05T06:19:23.005394Z"
    },
    "papermill": {
     "duration": 0.022983,
     "end_time": "2023-05-05T06:19:23.009362",
     "exception": false,
     "start_time": "2023-05-05T06:19:22.986379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable()\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, voc_size, emb_dim, enc_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(voc_size, emb_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        # out: A tensor of shape (batch_size, max_length, enc_units), which contains a vector of size enc_units for each word in the input sequence. \n",
    "        # These vectors represent the hidden states of the GRU layer at each time step.\n",
    "        out, state = self.gru(x, initial_state=hidden)\n",
    "        return out, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f7c23c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:23.029120Z",
     "iopub.status.busy": "2023-05-05T06:19:23.028029Z",
     "iopub.status.idle": "2023-05-05T06:19:23.630552Z",
     "shell.execute_reply": "2023-05-05T06:19:23.629015Z"
    },
    "papermill": {
     "duration": 0.615491,
     "end_time": "2023-05-05T06:19:23.633470",
     "exception": false,
     "start_time": "2023-05-05T06:19:23.017979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 22, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(voc_in_size, emb_dim, units, batch_size)\n",
    "sam_hidden = encoder.initialize_hidden_state()\n",
    "sam_output, sam_hidden = encoder(exm_in_bat, sam_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sam_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sam_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44476b58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:23.654036Z",
     "iopub.status.busy": "2023-05-05T06:19:23.652800Z",
     "iopub.status.idle": "2023-05-05T06:19:23.661521Z",
     "shell.execute_reply": "2023-05-05T06:19:23.660448Z"
    },
    "papermill": {
     "duration": 0.022156,
     "end_time": "2023-05-05T06:19:23.664363",
     "exception": false,
     "start_time": "2023-05-05T06:19:23.642207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.W1=tf.keras.layers.Dense(units)\n",
    "        self.W2=tf.keras.layers.Dense(units)\n",
    "        self.V=tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self,query,values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis)+self.W2(values)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights*values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "464ea06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:23.684267Z",
     "iopub.status.busy": "2023-05-05T06:19:23.682992Z",
     "iopub.status.idle": "2023-05-05T06:19:23.779042Z",
     "shell.execute_reply": "2023-05-05T06:19:23.777482Z"
    },
    "papermill": {
     "duration": 0.108997,
     "end_time": "2023-05-05T06:19:23.781945",
     "exception": false,
     "start_time": "2023-05-05T06:19:23.672948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 22, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sam_hidden, sam_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3154c329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:23.802389Z",
     "iopub.status.busy": "2023-05-05T06:19:23.801484Z",
     "iopub.status.idle": "2023-05-05T06:19:23.813161Z",
     "shell.execute_reply": "2023-05-05T06:19:23.811840Z"
    },
    "papermill": {
     "duration": 0.025569,
     "end_time": "2023-05-05T06:19:23.816439",
     "exception": false,
     "start_time": "2023-05-05T06:19:23.790870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable()\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, voc_size, emb_dim, dec_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(voc_size, emb_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units, \n",
    "                                       return_sequences=True, \n",
    "                                       return_state=True, \n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(voc_size)\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b192c76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:23.837061Z",
     "iopub.status.busy": "2023-05-05T06:19:23.835794Z",
     "iopub.status.idle": "2023-05-05T06:19:24.095616Z",
     "shell.execute_reply": "2023-05-05T06:19:24.094022Z"
    },
    "papermill": {
     "duration": 0.273698,
     "end_time": "2023-05-05T06:19:24.098943",
     "exception": false,
     "start_time": "2023-05-05T06:19:23.825245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 2416)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(voc_tar_size, emb_dim, units, batch_size)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)),sam_hidden, sam_output)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "094e7e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:24.119806Z",
     "iopub.status.busy": "2023-05-05T06:19:24.119083Z",
     "iopub.status.idle": "2023-05-05T06:19:24.132311Z",
     "shell.execute_reply": "2023-05-05T06:19:24.131116Z"
    },
    "papermill": {
     "duration": 0.027403,
     "end_time": "2023-05-05T06:19:24.135426",
     "exception": false,
     "start_time": "2023-05-05T06:19:24.108023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15edc7ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:24.155000Z",
     "iopub.status.busy": "2023-05-05T06:19:24.154539Z",
     "iopub.status.idle": "2023-05-05T06:19:24.163744Z",
     "shell.execute_reply": "2023-05-05T06:19:24.162555Z"
    },
    "papermill": {
     "duration": 0.02241,
     "end_time": "2023-05-05T06:19:24.166521",
     "exception": false,
     "start_time": "2023-05-05T06:19:24.144111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss=0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([target_lang.word_index['<sos>']]*batch_size,1)\n",
    "        for t in range(1,targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:,t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:,t],1)\n",
    "    \n",
    "    batch_loss = (loss/int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6765a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:19:24.185841Z",
     "iopub.status.busy": "2023-05-05T06:19:24.185409Z",
     "iopub.status.idle": "2023-05-05T06:23:27.589980Z",
     "shell.execute_reply": "2023-05-05T06:23:27.588314Z"
    },
    "papermill": {
     "duration": 243.42692,
     "end_time": "2023-05-05T06:23:27.602263",
     "exception": false,
     "start_time": "2023-05-05T06:19:24.175343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1   Loss: tf.Tensor(2.1396842, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(1, epochs+1):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch,(inp,targ)) in enumerate(ds.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    print('Epoch:',epoch,'  Loss:',total_loss/steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35eba28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:23:27.626154Z",
     "iopub.status.busy": "2023-05-05T06:23:27.624927Z",
     "iopub.status.idle": "2023-05-05T06:23:38.028671Z",
     "shell.execute_reply": "2023-05-05T06:23:38.026496Z"
    },
    "papermill": {
     "duration": 10.421067,
     "end_time": "2023-05-05T06:23:38.034469",
     "exception": false,
     "start_time": "2023-05-05T06:23:27.613402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('input_.pkl', 'wb') as f:\n",
    "    pickle.dump(input_lang, f)\n",
    "with open('target_.pkl', 'wb') as f:\n",
    "    pickle.dump(target_lang, f)\n",
    "\n",
    "tf.saved_model.save(encoder,'encoder')\n",
    "tf.saved_model.save(decoder,'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9268353b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:23:38.062363Z",
     "iopub.status.busy": "2023-05-05T06:23:38.061066Z",
     "iopub.status.idle": "2023-05-05T06:23:38.068336Z",
     "shell.execute_reply": "2023-05-05T06:23:38.067335Z"
    },
    "papermill": {
     "duration": 0.024029,
     "end_time": "2023-05-05T06:23:38.071163",
     "exception": false,
     "start_time": "2023-05-05T06:23:38.047134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_tags(sent):\n",
    "    return sent.split('<start>')[-1].split('<end>')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c7f8b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:23:38.093652Z",
     "iopub.status.busy": "2023-05-05T06:23:38.093120Z",
     "iopub.status.idle": "2023-05-05T06:23:38.105142Z",
     "shell.execute_reply": "2023-05-05T06:23:38.103829Z"
    },
    "papermill": {
     "duration": 0.027164,
     "end_time": "2023-05-05T06:23:38.107940",
     "exception": false,
     "start_time": "2023-05-05T06:23:38.080776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(sent):\n",
    "    sent = clean_text(sent)\n",
    "    inputs = [input_lang.word_index[i] for i in sent.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_len_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1,units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([target_lang.word_index['<sos>']],0)\n",
    "    for t in range(max_len_target):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += target_lang.index_word[predicted_id] + ' '\n",
    "        if target_lang.index_word[predicted_id] == '<eos>':\n",
    "            return remove_tags(result), remove_tags(sent)\n",
    "        dec_input = tf.expand_dims([predicted_id],0)\n",
    "    return remove_tags(result), remove_tags(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7efe001e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:23:38.129797Z",
     "iopub.status.busy": "2023-05-05T06:23:38.128542Z",
     "iopub.status.idle": "2023-05-05T06:23:38.135005Z",
     "shell.execute_reply": "2023-05-05T06:23:38.133892Z"
    },
    "papermill": {
     "duration": 0.021247,
     "end_time": "2023-05-05T06:23:38.138905",
     "exception": false,
     "start_time": "2023-05-05T06:23:38.117658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask(sent):\n",
    "    result, sent = evaluate(sent)\n",
    "    print('Que: ', sent.replace('<sos> ','').replace(' <eos>',''), '\\nAns: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5568f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:23:38.161299Z",
     "iopub.status.busy": "2023-05-05T06:23:38.160566Z",
     "iopub.status.idle": "2023-05-05T06:23:38.173656Z",
     "shell.execute_reply": "2023-05-05T06:23:38.172353Z"
    },
    "papermill": {
     "duration": 0.02862,
     "end_time": "2023-05-05T06:23:38.177387",
     "exception": false,
     "start_time": "2023-05-05T06:23:38.148767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "q, a = [], []\n",
    "with open('../input/simple-dialogs-for-chatbot/dialogs.txt','r') as f:\n",
    "    for line in f:\n",
    "        line = line.split('\\t')\n",
    "        q.append(line[0])\n",
    "        a.append(line[1].replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c231c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T06:23:38.199303Z",
     "iopub.status.busy": "2023-05-05T06:23:38.198529Z",
     "iopub.status.idle": "2023-05-05T06:23:38.383001Z",
     "shell.execute_reply": "2023-05-05T06:23:38.380241Z"
    },
    "papermill": {
     "duration": 0.200082,
     "end_time": "2023-05-05T06:23:38.386477",
     "exception": false,
     "start_time": "2023-05-05T06:23:38.186395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Que:  when \n",
      "Ans:  i <eos> \n"
     ]
    }
   ],
   "source": [
    "ask('when')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 283.801762,
   "end_time": "2023-05-05T06:23:41.222874",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-05T06:18:57.421112",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
